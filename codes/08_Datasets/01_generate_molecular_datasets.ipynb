{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : Generate QM9/ZINC dataset for PyTorch and DGL\n",
    "\n",
    "### Xavier Bresson <br>\n",
    "\n",
    "**Smile datasets**: Molecule is represented with smile/RDKit. The files are in folder QM9_smile/train_smile.txt, val_smile.txt, test_smile.txt <br>\n",
    "**PyTorch datasets**: Molecule is represented with PyTorch. The files are in folder QM9_pytorch/train_pytorch.pkl, val_pytorch.pkl, test_pytorch.pkl, atom_dict.pkl, bond_dict.pkl <br>\n",
    "**DGL datasets**: Molecule is represented with DGL. The files are in folder QM9_dgl/train_dgl.pkl, val_dgl.pkl, test_dgl.pkl <br>\n",
    "\n",
    "**PyTorch molecule structure**: A molecule object (our own class) that contains the following attributes:  \n",
    "◦ molecule[idx].num_atom : nb of atoms, an integer (N)  \n",
    "◦ molecule[idx].atom_type : pytorch tensor of size N, each element is an atom type, an integer between 0 and num_atom_type-1  \n",
    "◦ molecule[idx].atom_type_pe : pytorch tensor of size N, each element is an atom type positional encoding, an integer between 0 and num_atom-1  \n",
    "◦ molecule[idx].bond_type : pytorch tensor of size N x N, each element is a bond type, an integer between 0 and num_bond_type-1  \n",
    "◦ molecule[idx].bag_of_atoms : pytorch tensor of size num_atom_type, histogram of atoms in the molecule  \n",
    "◦ molecule[idx].logP_SA_cycle_normalized : the chemical property to regress, a pytorch float variable  \n",
    "◦ molecule[idx].smile : the smile representation of the molecule for rdkit, a string   \n",
    "◦ idx, an integer between 0 and num_molecules-1 representing the molecule index in the datasets  \n",
    "\n",
    "**DGL molecule structure**: A DGL structure that contains the following members:   \n",
    "◦ molecule[idx] : a tuple (dgl_graph, label) where label is logP_SA_cycle_normalized  \n",
    "◦ dgl_graph : a DGL object that contains  \n",
    "&nbsp; • sparse adjacency matrix  \n",
    "&nbsp; • the node feature with dgl_graph.ndata['feat'] (atom_type)  \n",
    "&nbsp; • the edge feature with dgl_graph.edata['feat'] (bond_type)    \n",
    "\n",
    "\n",
    "**QM9 statistics** <br>\n",
    "test set size : 5,000 <br>\n",
    "val set size : 10,000 <br>\n",
    "train set size : 118,879 <br>\n",
    "min/max molecule size : 4/9<br>\n",
    "\n",
    "**ZINC statistics** <br>\n",
    "test set size :    5,000 <br>\n",
    "val set size :    24,445 <br>\n",
    "train set size : 220,011 <br>\n",
    "min/max molecule size : 6/38 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/GML_May23_codes/codes/08_Datasets'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"path_to_file\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n",
    "    !pip install dgl # Install DGL\n",
    "    !pip install rdkit # Install RDKit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdmolops\n",
    "from utils import sascorer\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "import dgl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions to process smile and generate pytorch molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent of having or not aromaticity\n",
    "def clean_qm9_smiles(list_of_smiles):\n",
    "    new_list_of_smiles = []\n",
    "    for idx,smile in enumerate(list_of_smiles):\n",
    "        # remove brakets and CH2\n",
    "        smile = smile.replace('[C]', 'C')\n",
    "        smile = smile.replace('[N]', 'N')\n",
    "        smile = smile.replace('[O]', 'O')\n",
    "        smile = smile.replace('[CH]', 'C')\n",
    "        smile = smile.replace('[NH]', 'N')\n",
    "        smile = smile.replace('[CH2]', 'C')\n",
    "        # remove smile with non-connected compounds\n",
    "        #if '.' in smile:\n",
    "        #    continue\n",
    "        # remove non-connected compounds in smiles \n",
    "        smile = sorted(smile.split('.'), key=len, reverse=True)[0]\n",
    "        new_list_of_smiles.append(smile)\n",
    "    return new_list_of_smiles\n",
    "\n",
    "# independent of having or not aromaticity\n",
    "def remove_stereo_smiles(list_of_smiles):\n",
    "    for idx,smile in enumerate(list_of_smiles):\n",
    "        smile = smile.replace('\\\\' , \"\")\n",
    "        smile = smile.replace(\"/\", \"\") \n",
    "        list_of_smiles[idx] = smile\n",
    "    return list_of_smiles\n",
    "\n",
    "def from_smile_to_rdkit_smile(smile):\n",
    "    mol = Chem.MolFromSmiles(smile) # from arbitrary smile to mol\n",
    "    smile = Chem.MolToSmiles(mol) # from mol to rdkit smile\n",
    "    return smile\n",
    "\n",
    "# remove aromatic bonds (smiles are changed)\n",
    "def remove_aromatic_bonds(list_of_smiles):\n",
    "    for idx,smile in enumerate(list_of_smiles): \n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        Chem.Kekulize(mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "        smile = Chem.MolToSmiles(mol)\n",
    "        list_of_smiles[idx] = smile\n",
    "    return list_of_smiles\n",
    "\n",
    "def atom2symbol(rdkit_atom):\n",
    "    symbol = rdkit_atom.GetSymbol()\n",
    "    num_explicit_h = rdkit_atom.GetNumExplicitHs()\n",
    "    num_charges = rdkit_atom.GetFormalCharge()\n",
    "    if num_explicit_h!=0:\n",
    "        symbol = symbol + ' H' + str(num_explicit_h)\n",
    "    if num_charges==1:\n",
    "        symbol = symbol + ' +'\n",
    "    if num_charges==-1:\n",
    "        symbol = symbol + ' -'\n",
    "    if abs(num_charges) > 1:\n",
    "        'ERROR!: more than one charge'\n",
    "    return symbol\n",
    "\n",
    "# class of atom and bond dictionaries\n",
    "class Dictionary:\n",
    "    \"\"\"\n",
    "    word2idx and idx2word are mappings from words to idx and vice versa\n",
    "    word2idx is a dictionary\n",
    "    idx2word is a list\n",
    "    word2num_occurence compute the number of times a given word has been added to the dictionary\n",
    "    idx2num_occurence do the same, but with the index of the word rather than the word itself.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "        self.word2num_occurence = {}\n",
    "        self.idx2num_occurence = []\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            # dictionaries\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "            # stats\n",
    "            self.idx2num_occurence.append(0)\n",
    "            self.word2num_occurence[word] = 0\n",
    "        # increase counters    \n",
    "        self.word2num_occurence[word]+=1\n",
    "        self.idx2num_occurence[  self.word2idx[word]  ] += 1\n",
    "    def get_rid_of_rare_words(self, min_num_occurence):\n",
    "        new_idx2word = [ word for word in self.idx2word if self.word2num_occurence[word] >= min_num_occurence  ]\n",
    "        new_word2idx = { word: idx  for idx,word in enumerate(new_idx2word) }         \n",
    "        new_idx2num_occurence = [ self.word2num_occurence[word] for word in new_idx2word]   \n",
    "        new_word2num_occurence = { word: self.word2num_occurence[word]  for word in new_idx2word } \n",
    "        self.word2idx = new_word2idx\n",
    "        self.idx2word = new_idx2word\n",
    "        self.word2num_occurence = new_word2num_occurence\n",
    "        self.idx2num_occurence = new_idx2num_occurence\n",
    "    def show(self):\n",
    "        for idx, word in enumerate(self.idx2word):\n",
    "            print(idx,'\\t', word,'\\t number of occurences = {}'.format(self.idx2num_occurence[idx]))\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "    \n",
    "# take a lists of smiles and use it to augment existing atom and bond dictionaries\n",
    "def augment_dictionary(atom_dict, bond_dict, list_of_smiles ):\n",
    "    for idx,smile in enumerate(list_of_smiles):\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        Chem.Kekulize(mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "        for atom in mol.GetAtoms():\n",
    "            atom_dict.add_word( atom2symbol(atom) )\n",
    "        for bond in mol.GetBonds():\n",
    "            bond_dict.add_word( str(bond.GetBondType()) )\n",
    "\n",
    "# take three lists of smiles (train, val and test) and build atoms and bond dictionaries\n",
    "def make_dictionary(list_of_smiles_train, list_of_smiles_val, list_of_smiles_test):\n",
    "    atom_dict = Dictionary()\n",
    "    bond_dict = Dictionary()\n",
    "    bond_dict.add_word('NONE')\n",
    "    print('test..')\n",
    "    augment_dictionary(atom_dict, bond_dict, list_of_smiles_test )\n",
    "    print('val..')\n",
    "    augment_dictionary(atom_dict, bond_dict, list_of_smiles_val )  \n",
    "    print('train..')\n",
    "    augment_dictionary(atom_dict, bond_dict, list_of_smiles_train )\n",
    "    return atom_dict, bond_dict       \n",
    "\n",
    "# NOT independent of the property of aromaticity\n",
    "def contain_OOV_atom(smile, atom_dict ): \n",
    "    mybool = False\n",
    "    mol = Chem.MolFromSmiles(smile) \n",
    "    Chem.Kekulize(mol, clearAromaticFlags=True) # MUST remove aromatic bonds for OOV\n",
    "    for atom in mol.GetAtoms():\n",
    "        if atom2symbol(atom) not in atom_dict.word2idx:\n",
    "            mybool=True\n",
    "    return mybool\n",
    "\n",
    "# independent of having or not aromaticity\n",
    "def get_rid_of_OOV_smiles(list_of_smiles, atom_dict ):\n",
    "    new_list = []\n",
    "    OOV_list = []\n",
    "    for smiles in list_of_smiles:\n",
    "        if contain_OOV_atom(smiles, atom_dict ):\n",
    "            OOV_list.append(smiles)\n",
    "        else:\n",
    "            new_list.append(smiles)   \n",
    "    return new_list, OOV_list\n",
    "\n",
    "# logP\n",
    "def logP(mol):\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    return logp\n",
    "\n",
    "# SA  \n",
    "def SA(mol):\n",
    "    sa = sascorer.calculateScore(mol)\n",
    "    return sa\n",
    "\n",
    "# cycle\n",
    "def compute_cycle(smile):\n",
    "    cycle_list = nx.cycle_basis(nx.Graph(rdmolops.GetAdjacencyMatrix(Chem.MolFromSmiles(smile))))\n",
    "    if len(cycle_list) == 0:\n",
    "        cycle_length = 0\n",
    "    else:\n",
    "        cycle_length = max([ len(j) for j in cycle_list ])\n",
    "    if cycle_length <= 6:\n",
    "        cycle_length = 0\n",
    "    else:\n",
    "        cycle_length = cycle_length - 6\n",
    "    cycle_score = -cycle_length\n",
    "    return cycle_score\n",
    "\n",
    "def Cycle(mol):\n",
    "    smile = Chem.MolToSmiles(mol) # mol is supposed to be a valid rdkit molecule\n",
    "    cycle = float(compute_cycle(smile))\n",
    "    return cycle\n",
    "\n",
    "def logP_SA(mol):\n",
    "    logp = logP(mol)\n",
    "    sa = SA(mol)\n",
    "    return logp - sa\n",
    "\n",
    "def compute_stat_chem_prop_train_mol(smile_train):\n",
    "    logP_values = []\n",
    "    SA_values = []\n",
    "    cycle_values = []\n",
    "    for smile in smile_train: \n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        logP_values.append(logP(mol))\n",
    "        SA_values.append(-SA(mol))\n",
    "        cycle_values.append(Cycle(mol))\n",
    "    # stats\n",
    "    logP_values = torch.tensor(logP_values)\n",
    "    logP_values_mean = logP_values.mean().item()\n",
    "    logP_values_std = logP_values.std().item()\n",
    "    SA_values = torch.tensor(SA_values)\n",
    "    SA_values_mean = SA_values.mean().item()\n",
    "    SA_values_std = SA_values.std().item()\n",
    "    cycle_values = torch.tensor(cycle_values)\n",
    "    cycle_values_mean = cycle_values.mean().item()\n",
    "    cycle_values_std = cycle_values.std().item()\n",
    "    train_stat_mol_prop = [logP_values_mean, logP_values_std, SA_values_mean, SA_values_std, cycle_values_mean, cycle_values_std]\n",
    "    return train_stat_mol_prop\n",
    "\n",
    "class Molecule:\n",
    "    \"\"\"\n",
    "    A molecule object contains the following attributes:\n",
    "        ; molecule.num_atom : nb of atoms, an integer (N)\n",
    "        ; molecule.atom_type : pytorch tensor of size N, each element is an atom type, an integer between 0 and num_atom_type-1\n",
    "        ; molecule.atom_type_pe : pytorch tensor of size N, each element is an atom type positional encoding, an integer between 0 and num_atom-1\n",
    "        ; molecule.bond_type : pytorch tensor of size N x N, each element is a bond type, an integer between 0 and num_bond_type-1 \n",
    "        ; molecule.bag_of_atoms : pytorch tensor of size num_atom_type, histogram of atoms in the molecule\n",
    "        ; molecule.logP_SA_cycle_normalized : the chemical property to regress, a pytorch float variable\n",
    "        ; molecule.smile : the smile representation of the molecule for rdkit, a string   \n",
    "    \"\"\"\n",
    "    def __init__(self, num_atom, num_atom_type):\n",
    "        self.num_atom       = num_atom\n",
    "        self.atom_type      = torch.zeros( num_atom , dtype=torch.long )\n",
    "        self.atom_type_pe   = torch.zeros( num_atom , dtype=torch.long )\n",
    "        self.bond_type      = torch.zeros( num_atom , num_atom, dtype=torch.long )\n",
    "        self.bag_of_atoms   = torch.zeros( num_atom_type, dtype=torch.long)\n",
    "        self.logP_SA        = torch.zeros( 1, dtype=torch.float)\n",
    "        self.logP_SA_cycle_normalized  = torch.zeros( 1, dtype=torch.float)\n",
    "        self.smile  = ''\n",
    "    def set_bag_of_atoms(self):\n",
    "        for tp in self.atom_type:\n",
    "                self.bag_of_atoms[tp.item()] += 1\n",
    "    def set_atom_type_pe(self):\n",
    "        histogram={}\n",
    "        for idx, tp in enumerate(self.atom_type):\n",
    "            tpp=tp.item()\n",
    "            if tpp not in histogram:\n",
    "                histogram[tpp] = 0\n",
    "            else:\n",
    "                histogram[tpp] += 1\n",
    "            self.atom_type_pe[idx] = histogram[tpp]\n",
    "    def shuffle_indexing(self):\n",
    "        idx = torch.randperm(self.num_atom)\n",
    "        self.atom_type = self.atom_type[idx]\n",
    "        self.atom_type_pe = self.atom_type_pe[idx]\n",
    "        self.bond_type = self.bond_type[idx][:,idx]\n",
    "        return idx\n",
    "    def __len__(self):\n",
    "        return self.num_atom\n",
    "    \n",
    "# convert smile molecule to pytorch molecule \n",
    "def from_smile_to_pymol(smile, atom_dict, bond_dict, stat_prop, remove_aromatic=False):\n",
    "    \"\"\"\n",
    "    This function take a smile an create a \"pytorch molecule\". \n",
    "    In order to do this we need to have some mapping between \n",
    "    type of atom and integers, and type of bonds an integer.\n",
    "    (see dictionary class below)\n",
    "\n",
    "    Input: a smile \n",
    "           a dictionary of atoms (that gives mapping of the type C --> 0, N --> 1, etc...)\n",
    "           a dictionary of bonds (that gives mapping of the type SINGLE --> 0,  AROMATIC --> 1, etc...)\n",
    "           \n",
    "    Output: return a pytorch molecule\n",
    "    \"\"\"\n",
    "    rdkit_mol = Chem.MolFromSmiles(smile)\n",
    "    if remove_aromatic==True:\n",
    "        Chem.Kekulize(rdkit_mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "    N = rdkit_mol.GetNumAtoms()\n",
    "    num_atom_type = len(atom_dict)\n",
    "    pytorch_mol = Molecule(N,num_atom_type)   \n",
    "    # set the bond_type attribute\n",
    "    for bond in rdkit_mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        bond_type_idx=bond_dict.word2idx[ str(bond.GetBondType()) ]\n",
    "        pytorch_mol.bond_type[i,j]= bond_type_idx\n",
    "        pytorch_mol.bond_type[j,i]= bond_type_idx      \n",
    "    # set the atom_type attribute\n",
    "    for atom in rdkit_mol.GetAtoms():\n",
    "        i=atom.GetIdx()\n",
    "        pytorch_mol.atom_type[i]=atom_dict.word2idx[ atom2symbol(atom) ]      \n",
    "    # set the atom_type_pe and bag of atoms attributes\n",
    "    pytorch_mol.set_bag_of_atoms() \n",
    "    pytorch_mol.set_atom_type_pe()\n",
    "    # set the target chemical property :  y(m) = logP(m) − SA(m) + cycle(m)\n",
    "    rdkit_mol = Chem.MolFromSmiles(smile) # do *not* remove aromatic bonds when logP_SA is computed \n",
    "    pytorch_mol.logP_SA = torch.Tensor([logP_SA(rdkit_mol)]) \n",
    "    logP_values_mean = stat_prop[0] \n",
    "    logP_values_std = stat_prop[1]\n",
    "    SA_values_mean = stat_prop[2]\n",
    "    SA_values_std = stat_prop[3]\n",
    "    cycle_values_mean = stat_prop[4]\n",
    "    cycle_values_std = stat_prop[5]\n",
    "    logP_value_normalized = (logP(rdkit_mol)-logP_values_mean)/logP_values_std\n",
    "    SA_value_normalized = (-SA(rdkit_mol)-SA_values_mean)/SA_values_std\n",
    "    cycle_value_normalized = (Cycle(rdkit_mol)-cycle_values_mean)/cycle_values_std\n",
    "    logP_SA_cycle_normalized = logP_value_normalized + SA_value_normalized + cycle_value_normalized\n",
    "    pytorch_mol.logP_SA_cycle_normalized = torch.Tensor([logP_SA_cycle_normalized])\n",
    "    pytorch_mol.smile = smile\n",
    "    return pytorch_mol\n",
    "\n",
    "def symbol2atom(aug_symb):\n",
    "    mylist=aug_symb.split()\n",
    "    atom = Chem.Atom(mylist[0])\n",
    "    if '+' in mylist:\n",
    "        atom.SetFormalCharge(1)\n",
    "    if '-' in mylist:\n",
    "        atom.SetFormalCharge(-1)\n",
    "    if 'H1' in mylist:\n",
    "        atom.SetNumExplicitHs(1)   \n",
    "    if 'H2' in mylist:\n",
    "        atom.SetNumExplicitHs(2)    \n",
    "    if 'H3' in mylist:\n",
    "        atom.SetNumExplicitHs(3)\n",
    "    return atom\n",
    "\n",
    "def from_mol_to_smile(mol, remove_aromatic=False):\n",
    "    if remove_aromatic==True:\n",
    "        Chem.Kekulize(mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "    smile = Chem.MolToSmiles(mol)\n",
    "    return smile\n",
    "\n",
    "def from_pymol_to_smile(pymol, atom_dict, bond_dict, remove_aromatic=False):\n",
    "    N = pymol.num_atom \n",
    "    mol = Chem.RWMol()\n",
    "    for tp in pymol.atom_type:\n",
    "        symbol = atom_dict.idx2word[ tp.item() ]\n",
    "        mol.AddAtom( symbol2atom(symbol) )\n",
    "    for i in range(0,N): \n",
    "        for j in range(i+1,N): \n",
    "            tp = pymol.bond_type[i,j].item()\n",
    "            bond_stg = bond_dict.idx2word[tp]\n",
    "            if bond_stg!='NONE':\n",
    "                if bond_stg=='SINGLE':\n",
    "                    mol.AddBond(i, j, Chem.rdchem.BondType.SINGLE)\n",
    "                if bond_stg=='DOUBLE':\n",
    "                    mol.AddBond(i, j, Chem.rdchem.BondType.DOUBLE)\n",
    "                if bond_stg=='TRIPLE':\n",
    "                    mol.AddBond(i, j, Chem.rdchem.BondType.TRIPLE)\n",
    "                if bond_stg=='AROMATIC':\n",
    "                    #print('ISSUE: MUST BE NO AROMATIC BONDS !!!!')\n",
    "                    mol.AddBond(i, j, Chem.rdchem.BondType.AROMATIC)\n",
    "    smile = from_mol_to_smile(mol,remove_aromatic)\n",
    "    return smile\n",
    "\n",
    "def rm_stereo(smile, remove_aromatic=False):\n",
    "    smile = smile.replace('\\\\' , \"\")\n",
    "    smile = smile.replace(\"/\", \"\") \n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if remove_aromatic==True:\n",
    "        Chem.Kekulize(mol, clearAromaticFlags=True) # remove aromatic bonds\n",
    "    smile = Chem.MolToSmiles(mol, isomericSmiles=False) # remove stereo\n",
    "    return smile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate pytorch datasets from original smile datasets \n",
    "Note: I do not use the full datasets for the course, only a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert csv files to panda dataframes\n",
      "                  smiles\n",
      "0  N[C]1[N]C2CC1[N][C]2N\n",
      "1            CCn1cncc1OC\n",
      "2          OC1CCCCC(O)C1\n",
      "3         CCC1C2OCC12C=O\n",
      "4       CN1C(=O)CN=C1C=O\n",
      "Extract subsets of datasets\n",
      "                  smiles\n",
      "0  N[C]1[N]C2CC1[N][C]2N\n",
      "1            CCn1cncc1OC\n",
      "2          OC1CCCCC(O)C1\n",
      "3         CCC1C2OCC12C=O\n",
      "4       CN1C(=O)CN=C1C=O\n",
      "Convert the panda data frame into a list of smiles\n",
      "['N[C]1[N]C2CC1[N][C]2N', 'CCn1cncc1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "clean QM9 smiles\n",
      "['NC1NC2CC1NC2N', 'CCn1cncc1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "remove stereo symbols in smiles\n",
      "['NC1NC2CC1NC2N', 'CCn1cncc1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "Change original smiles to rdkit-smiles\n",
      "['NC1NC2CC1NC2N', 'CCn1cncc1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "Remove aromatic bonds\n",
      "['NC1NC2CC1NC2N', 'CCN1C=NC=C1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "Building atom and bond dictionaries..\n",
      "test..\n",
      "val..\n",
      "train..\n",
      "0 \t N \t number of occurences = 2433\n",
      "1 \t C \t number of occurences = 15244\n",
      "2 \t O \t number of occurences = 3333\n",
      "3 \t F \t number of occurences = 76\n",
      "4 \t N H3 + \t number of occurences = 2\n",
      "5 \t O - \t number of occurences = 4\n",
      "6 \t C H1 - \t number of occurences = 1\n",
      "7 \t N + \t number of occurences = 2\n",
      "8 \t N - \t number of occurences = 2\n",
      "9 \t N H1 - \t number of occurences = 1\n",
      "10 \t C + \t number of occurences = 1\n",
      "11 \t O + \t number of occurences = 1\n",
      "12 \t N H2 + \t number of occurences = 1\n",
      "['N', 'C', 'O', 'F', 'N H3 +', 'O -', 'C H1 -', 'N +', 'N -', 'N H1 -', 'C +', 'O +', 'N H2 +']\n",
      "{'N': 0, 'C': 1, 'O': 2, 'F': 3, 'N H3 +': 4, 'O -': 5, 'C H1 -': 6, 'N +': 7, 'N -': 8, 'N H1 -': 9, 'C +': 10, 'O +': 11, 'N H2 +': 12}\n",
      "['NONE', 'SINGLE', 'DOUBLE', 'TRIPLE']\n",
      "{'NONE': 0, 'SINGLE': 1, 'DOUBLE': 2, 'TRIPLE': 3}\n",
      "Get rid of rare coumpounds and only keep the following\n",
      "0 \t N \t number of occurences = 2433\n",
      "1 \t C \t number of occurences = 15244\n",
      "2 \t O \t number of occurences = 3333\n",
      "3 \t F \t number of occurences = 76\n",
      "4 \t N H3 + \t number of occurences = 2\n",
      "5 \t O - \t number of occurences = 4\n",
      "6 \t C H1 - \t number of occurences = 1\n",
      "7 \t N + \t number of occurences = 2\n",
      "8 \t N - \t number of occurences = 2\n",
      "9 \t N H1 - \t number of occurences = 1\n",
      "10 \t C + \t number of occurences = 1\n",
      "11 \t O + \t number of occurences = 1\n",
      "12 \t N H2 + \t number of occurences = 1\n",
      "Get rid of OOV smiles..\n",
      "test set size : \t 200 (0 were discarded)\n",
      "val set size : \t 200 (0 were discarded)\n",
      "train set size : \t 2000 (0 were discarded)\n",
      "Compute statistical chemical properties of train molecules\n",
      "logP_values_mean, logP_values_std, SA_values_mean, SA_values_std, cycle_values_mean, cycle_values_std:\n",
      " [0.3201034367084503, 0.978784441947937, -4.224914073944092, 0.9502790570259094, -0.04100000113248825, 0.23096682131290436]\n",
      "Convert smiles to pytorch molecules...\n",
      "test..\n",
      "val..\n",
      "train..\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 0, 1, 1, 2, 3, 2, 4, 3])\n",
      "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
      "tensor([4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "NC1NC2CC1NC2N\n",
      "logP_SA tensor([-8.3573])\n",
      "logP_SA_cycle_normalized tensor([-4.4335])\n",
      "smile_test NC1NC2CC1NC2N\n",
      "Sanity check: convert pytorch molecules back to smiles and check we recover the original smiles\n",
      "test..\n",
      "val..\n",
      "train..\n",
      "['NC1NC2CC1NC2N', 'CCN1C=NC=C1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "['NC1NC2CC1NC2N', 'CCN1C=NC=C1OC', 'OC1CCCCC(O)C1', 'CCC1C2OCC12C=O', 'CN1C(=O)CN=C1C=O']\n",
      "percentage of correct smiles --> pytorch molecules --> smiles: test/val/train 100.0%/100.0%/100.0%\n",
      "Saving pytorch molecules to folder : QM9_pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: QM9_pytorch: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 34.284770011901855\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "# folders\n",
    "data_folder_smile = 'QM9_smile'\n",
    "data_folder_pytorch = 'QM9_pytorch' \n",
    "# data_folder_smile = 'ZINC_smile'\n",
    "# data_folder_pytorch = 'ZINC_pytorch' \n",
    "\n",
    "print('Convert csv files to panda dataframes')\n",
    "df_train = pd.read_csv(data_folder_smile + '/train_smile.txt')\n",
    "df_val = pd.read_csv(data_folder_smile +'/valid_smile.txt')\n",
    "df_test = pd.read_csv(data_folder_smile + '/test_smile.txt')\n",
    "# df_train = pd.read_csv(data_folder_smile + '/test_smile.txt') # DEBUG !\n",
    "# df_val = pd.read_csv(data_folder_smile +'/test_smile.txt')   # DEBUG !\n",
    "# df_test = pd.read_csv(data_folder_smile + '/test_smile.txt')  # DEBUG !\n",
    "print(df_test[:5])\n",
    "\n",
    "print('Extract subsets of datasets') # comment the following lines to use full datasets <==========\n",
    "                                     # Subsets are for teaching purpose\n",
    "df_train = df_train[:2000] # truncated dataset !\n",
    "df_val = df_val[:200]      # truncated dataset !\n",
    "df_test = df_test[:200]    # truncated dataset !\n",
    "print(df_test[:5])\n",
    "\n",
    "print('Convert the panda data frame into a list of smiles')\n",
    "smile_train = [ df_train.loc[i,'smiles'] for i in df_train.index  ]\n",
    "smile_val   = [ df_val.loc[i,'smiles']   for i in df_val.index    ]\n",
    "smile_test  = [ df_test.loc[i,'smiles']  for i in df_test.index   ]\n",
    "print(smile_test[:5])\n",
    "\n",
    "# Change QM9 smiles : [C]=>C, [N]=>N, [O]=>O, [CH]=>C, [NH]=>N\n",
    "print('clean QM9 smiles')\n",
    "smile_train = clean_qm9_smiles(smile_train)\n",
    "smile_val = clean_qm9_smiles(smile_val)\n",
    "smile_test = clean_qm9_smiles(smile_test) \n",
    "print(smile_test[:5]) \n",
    "\n",
    "# Clean stereo smiles\n",
    "print('remove stereo symbols in smiles')\n",
    "smile_train = remove_stereo_smiles(smile_train)\n",
    "smile_val = remove_stereo_smiles(smile_val)\n",
    "smile_test = remove_stereo_smiles(smile_test)   \n",
    "print(smile_test[:5]) \n",
    "\n",
    "print('Change original smiles to rdkit-smiles')\n",
    "smile_train = [ from_smile_to_rdkit_smile(smile) for smile in smile_train ]\n",
    "smile_val =   [ from_smile_to_rdkit_smile(smile) for smile in smile_val ]\n",
    "smile_test =  [ from_smile_to_rdkit_smile(smile) for smile in smile_test ]\n",
    "print(smile_test[:5]) \n",
    "\n",
    "print('Remove aromatic bonds')\n",
    "smile_train = remove_aromatic_bonds(smile_train)\n",
    "smile_val = remove_aromatic_bonds(smile_val)\n",
    "smile_test = remove_aromatic_bonds(smile_test)\n",
    "print(smile_test[:5]) \n",
    "\n",
    "# Use the lists of smiles to build dictionaries of atoms and bonds\n",
    "print('Building atom and bond dictionaries..')\n",
    "atom_dict, bond_dict = make_dictionary(smile_train, smile_val, smile_test)\n",
    "atom_dict.show()\n",
    "print(atom_dict.idx2word)\n",
    "print(atom_dict.word2idx)\n",
    "print(bond_dict.idx2word)\n",
    "print(bond_dict.word2idx)\n",
    "\n",
    "# Trim dataset\n",
    "print('Get rid of rare coumpounds and only keep the following') \n",
    "#atom_dict.get_rid_of_rare_words(100) # if this line is commented then all coumpounds are kept\n",
    "                                      # comment out for getting rid of rare coumpounds with threshold frequency\n",
    "atom_dict.show()\n",
    "\n",
    "print('Get rid of OOV smiles..')\n",
    "smile_test,  OOV_smile_test  = get_rid_of_OOV_smiles( smile_test,  atom_dict )\n",
    "print('test set size : \\t {} ({} were discarded)'.format( len(smile_test) ,  len(OOV_smile_test)) )\n",
    "smile_val,   OOV_smile_val   = get_rid_of_OOV_smiles( smile_val,   atom_dict )\n",
    "print('val set size : \\t {} ({} were discarded)'.format( len(smile_val) ,  len(OOV_smile_val)) )\n",
    "smile_train, OOV_smile_train = get_rid_of_OOV_smiles( smile_train, atom_dict )\n",
    "print('train set size : \\t {} ({} were discarded)'.format( len(smile_train) ,  len(OOV_smile_train)) )\n",
    "        \n",
    "# Compute chemical properties of train molecules (logP, SA, cycle)  \n",
    "print('Compute statistical chemical properties of train molecules')\n",
    "train_stat_mol_prop = compute_stat_chem_prop_train_mol(smile_train)\n",
    "print('logP_values_mean, logP_values_std, SA_values_mean, SA_values_std, cycle_values_mean, cycle_values_std:\\n',train_stat_mol_prop)\n",
    "\n",
    "# Convert the lists of smiles into lists of pytorch molecules\n",
    "print('Convert smiles to pytorch molecules...')\n",
    "stat = train_stat_mol_prop\n",
    "print('test..')\n",
    "test  = [ from_smile_to_pymol(smile,atom_dict,bond_dict,stat,True) for smile in smile_test  ]\n",
    "#test  = [ Smiles2Mol(smile , atom_dict, bond_dict) for smile in smile_test  ]\n",
    "print('val..')\n",
    "val   = [ from_smile_to_pymol(smile,atom_dict,bond_dict,stat,True) for smile in smile_val   ]\n",
    "#val   = [ Smiles2Mol(smile , atom_dict, bond_dict) for smile in smile_val   ]\n",
    "print('train..')\n",
    "train = [ from_smile_to_pymol(smile,atom_dict,bond_dict,stat,True) for smile in smile_train ]\n",
    "#train = [ Smiles2Mol(smile , atom_dict, bond_dict) for smile in smile_train ]\n",
    "print(test[0].atom_type)\n",
    "print(test[0].atom_type_pe)\n",
    "print(test[0].bond_type)\n",
    "print(test[0].bag_of_atoms)\n",
    "print(test[0].smile)\n",
    "# properties given molecules : \n",
    "# logP : water-octanal partition coefficient\n",
    "# SA : synthetic accessibility score\n",
    "# QED : Qualitative Estimate of Drug-likeness\n",
    "# logP_SA = logP − SA\n",
    "print('logP_SA',test[0].logP_SA)\n",
    "print('logP_SA_cycle_normalized',test[0].logP_SA_cycle_normalized)\n",
    "print('smile_test',smile_test[0])\n",
    "\n",
    "# Sanity check : smile => pytorch => smile\n",
    "print('Sanity check: convert pytorch molecules back to smiles and check we recover the original smiles')\n",
    "print('test..')\n",
    "smile_test2  = [ from_pymol_to_smile(pymol,atom_dict,bond_dict,True) for pymol in test  ]\n",
    "print('val..')\n",
    "smile_val2  = [ from_pymol_to_smile(pymol,atom_dict,bond_dict,True) for pymol in val  ]\n",
    "print('train..')\n",
    "smile_train2  = [ from_pymol_to_smile(pymol,atom_dict,bond_dict,True) for pymol in train  ]\n",
    "print(smile_test[:5]) \n",
    "print(smile_test2[:5]) \n",
    "def accuracy_btw_smiles(smiles_list1, smiles_list2):\n",
    "    count=0\n",
    "    for idx,sm in enumerate(smiles_list1):\n",
    "        if rm_stereo(sm,True) == smiles_list2[idx]:\n",
    "            count+=1\n",
    "            #print('idx:',idx,' Smile:',rm_stereo(sm),' Smile=>mol=>smile:',smiles_list2[idx])\n",
    "        else:\n",
    "            #print('')\n",
    "            print('idx:',idx,' Smile:',rm_stereo(sm),' Smile=>mol=>smile:',smiles_list2[idx])\n",
    "    return count/len(smiles_list1)\n",
    "acc_test = accuracy_btw_smiles(smile_test, smile_test2)\n",
    "acc_val = accuracy_btw_smiles(smile_val, smile_val2)\n",
    "acc_train = accuracy_btw_smiles(smile_train, smile_train2)\n",
    "print('percentage of correct smiles --> pytorch molecules --> smiles: test/val/train {}%/{}%/{}%'.format(\n",
    "    acc_test*100, acc_val*100, acc_train*100))\n",
    "\n",
    "# Saving\n",
    "print('Saving pytorch molecules to folder : ' + data_folder_pytorch )\n",
    "os.system(\"mkdir \" + data_folder_pytorch )\n",
    "with open(data_folder_pytorch + \"/atom_dict.pkl\",\"wb\") as f:\n",
    "    pickle.dump(atom_dict,f)\n",
    "with open(data_folder_pytorch + \"/bond_dict.pkl\",\"wb\") as f:\n",
    "    pickle.dump(bond_dict, f)\n",
    "with open(data_folder_pytorch + \"/test_pytorch.pkl\",\"wb\") as f:\n",
    "    pickle.dump(test,f)\n",
    "with open(data_folder_pytorch +  \"/val_pytorch.pkl\",\"wb\") as f:\n",
    "    pickle.dump(val,f)\n",
    "with open(data_folder_pytorch +  \"/train_pytorch.pkl\",\"wb\") as f:\n",
    "    pickle.dump(train,f)\n",
    "print('Time:',time.time()-start)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print pytorch molecule and visualize with rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN1C(=O)CN=C1C=O\n",
      "tensor([1, 0, 1, 2, 1, 0, 1, 1, 2])\n",
      "tensor([0, 0, 1, 0, 2, 1, 3, 4, 1])\n",
      "9\n",
      "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 1, 0, 2, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 2, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 2, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 2, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 2],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 2, 0]])\n",
      "tensor([2, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([-0.4989])\n",
      "CN1C(=O)CN=C1C=O\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fa11cc0ff40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 4\n",
    "\n",
    "print(test[idx].smile)\n",
    "print(test[idx].atom_type)\n",
    "print(test[idx].atom_type_pe)\n",
    "print(test[idx].num_atom)\n",
    "print(test[idx].bond_type)\n",
    "print(test[idx].bag_of_atoms)\n",
    "print(test[idx].logP_SA_cycle_normalized)\n",
    "print(test[idx].smile)\n",
    "\n",
    "mol = Chem.MolFromSmiles(test[idx].smile)\n",
    "mol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pytorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "QM9_pytorch/\n",
      "Time: 1.2087969779968262\n",
      "['N', 'C', 'O', 'F', 'N H3 +', 'O -', 'C H1 -', 'N +', 'N -', 'N H1 -', 'C +', 'O +', 'N H2 +']\n",
      "{'N': 0, 'C': 1, 'O': 2, 'F': 3, 'N H3 +': 4, 'O -': 5, 'C H1 -': 6, 'N +': 7, 'N -': 8, 'N H1 -': 9, 'C +': 10, 'O +': 11, 'N H2 +': 12}\n",
      "['NONE', 'SINGLE', 'DOUBLE', 'TRIPLE']\n",
      "{'NONE': 0, 'SINGLE': 1, 'DOUBLE': 2, 'TRIPLE': 3}\n",
      "13 4\n",
      "tensor([1, 1, 2, 1, 1, 1, 1])\n",
      "tensor([0, 1, 0, 2, 3, 4, 5])\n",
      "tensor([[0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0]])\n",
      "tensor([0, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1.5990])\n",
      "CC(O)C1CC1C\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "start = time.time()\n",
    "\n",
    "data_folder_pytorch = 'QM9_pytorch/'\n",
    "# data_folder_pytorch = 'ZINC_pytorch/'\n",
    "print(data_folder_pytorch)\n",
    "\n",
    "with open(data_folder_pytorch+\"atom_dict.pkl\",\"rb\") as f:\n",
    "    atom_dict=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"bond_dict.pkl\",\"rb\") as f:\n",
    "    bond_dict=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"test_pytorch.pkl\",\"rb\") as f:\n",
    "    test=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"val_pytorch.pkl\",\"rb\") as f:\n",
    "    val=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"train_pytorch.pkl\",\"rb\") as f:\n",
    "    train=pickle.load(f)\n",
    "print('Time:',time.time()-start)\n",
    "\n",
    "print(atom_dict.idx2word)\n",
    "print(atom_dict.word2idx)\n",
    "print(bond_dict.idx2word)\n",
    "print(bond_dict.word2idx)\n",
    "\n",
    "num_atom_type = len(atom_dict.idx2word)\n",
    "num_bond_type = len(bond_dict.idx2word)\n",
    "print(num_atom_type, num_bond_type)\n",
    "\n",
    "idx = 45\n",
    "print(train[idx].atom_type)\n",
    "print(train[idx].atom_type_pe)\n",
    "print(train[idx].bond_type)\n",
    "print(train[idx].bag_of_atoms)\n",
    "print(train[idx].logP_SA_cycle_normalized)\n",
    "print(train[idx].smile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing molecules per size...\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "# Organize data into group of of molecules of fixed sized\n",
    "# For example, train is a dictionary\n",
    "# And train[22] is a list containing all the molecules of size 22  \n",
    "print(\"Organizing molecules per size...\")\n",
    "\n",
    "def group_molecules_per_size(dataset):\n",
    "    mydict={}\n",
    "    for mol in dataset:\n",
    "        if len(mol) not in mydict:\n",
    "            mydict[len(mol)]=[]\n",
    "        mydict[len(mol)].append(mol)\n",
    "    return mydict\n",
    "\n",
    "test_group  = group_molecules_per_size(test)\n",
    "val_group   = group_molecules_per_size(val)\n",
    "train_group = group_molecules_per_size(train)\n",
    "print(len(train_group[8])) # QM9\n",
    "# print(len(train_group[28])) # ZINC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max num atoms =  9\n"
     ]
    }
   ],
   "source": [
    "# what is the biggest molecule in the train set\n",
    "max_mol_sz= max(list( train_group.keys()))\n",
    "print('Max num atoms = ', max_mol_sz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "number of molecule of size 4: \t 2\n",
      "number of molecule of size 5: \t 2\n",
      "number of molecule of size 6: \t 13\n",
      "number of molecule of size 7: \t 37\n",
      "number of molecule of size 8: \t 282\n",
      "number of molecule of size 9: \t 1664\n",
      "Val\n",
      "number of molecule of size 7: \t 6\n",
      "number of molecule of size 8: \t 28\n",
      "number of molecule of size 9: \t 166\n",
      "Test\n",
      "number of molecule of size 6: \t 1\n",
      "number of molecule of size 7: \t 3\n",
      "number of molecule of size 8: \t 37\n",
      "number of molecule of size 9: \t 159\n"
     ]
    }
   ],
   "source": [
    "# distribution w.r.t. molecule size\n",
    "print('Train')\n",
    "data = train_group\n",
    "for nb_atom in range(max_mol_sz+1):\n",
    "    try: \n",
    "        print('number of molecule of size {}: \\t {}'.format(nb_atom, len(data[nb_atom])))\n",
    "    except:\n",
    "        pass\n",
    "print('Val')\n",
    "data = val_group\n",
    "for nb_atom in range(max_mol_sz+1):\n",
    "    try: \n",
    "        print('number of molecule of size {}: \\t {}'.format(nb_atom, len(data[nb_atom])))\n",
    "    except:\n",
    "        pass\n",
    "print('Test')\n",
    "data = test_group\n",
    "for nb_atom in range(max_mol_sz+1):\n",
    "    try: \n",
    "        print('number of molecule of size {}: \\t {}'.format(nb_atom, len(data[nb_atom])))\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate batch of pytorch molecules of same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to help drawing batches of molecules having the same size\n",
    "class MoleculeSampler:\n",
    "    \"\"\"\n",
    "    The dataset is a dictionary where the keys are the molecule sizes, and\n",
    "    the values are lists of pytorch molecule of the given size.\n",
    "    The MoleculeSampler will choose a size at random, and then provide the bs indices\n",
    "    of the molecules of this size to be drawn.\n",
    "\n",
    "    ATTRIBUTE:\n",
    "\n",
    "    bs: batch size\n",
    "\n",
    "    num_mol: (dictionary) key = size \n",
    "                          value = number of molecules of this size\n",
    "\n",
    "    counter: (dictionary) key   = size\n",
    "                          value = number of molecules of this size that have already been processed\n",
    "\n",
    "    order:   (dictionary) key = size\n",
    "                                value= np-array describing in which order \n",
    "                                       the molecules of this given size are going to be vistited                         \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, organized_dataset, bs , shuffle=True):  \n",
    "        self.bs=bs\n",
    "        self.num_mol =  { sz: len(list_of_mol)  for sz , list_of_mol in organized_dataset.items() }\n",
    "        self.counter = { sz: 0   for sz in organized_dataset }\n",
    "        if shuffle:\n",
    "            self.order = { sz: np.random.permutation(num)  for sz , num in self.num_mol.items() }\n",
    "        else:\n",
    "            self.order = { sz: np.arange(num)  for sz , num in self.num_mol.items() } \n",
    "\n",
    "\n",
    "    def compute_num_batches_remaining(self):\n",
    "        return {sz:  ( self.num_mol[sz] - self.counter[sz] ) // self.bs  for sz in self.num_mol}\n",
    "\n",
    "    def choose_molecule_size(self):\n",
    "        num_batches= self.compute_num_batches_remaining()\n",
    "        possible_sizes =  np.array( list( num_batches.keys()) )\n",
    "        prob           =  np.array( list( num_batches.values() )   ) \n",
    "        prob =  prob / prob.sum()\n",
    "        sz   = np.random.choice(  possible_sizes , p=prob )\n",
    "        return sz\n",
    "\n",
    "    def is_empty(self):\n",
    "        num_batches= self.compute_num_batches_remaining()\n",
    "        return sum( num_batches.values() ) == 0\n",
    "\n",
    "    def draw_batch_of_molecules(self,sz):  \n",
    "        indices=self.order[sz][ self.counter[sz] : self.counter[sz] + self.bs]\n",
    "        self.counter[sz] += self.bs  \n",
    "        return indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[1004  815 1065    1  836 1257  308  520  145  855   58  716  476  108\n",
      " 1245  562  773 1599   98  536  590  916 1300 1524 1089 1640  446  513\n",
      "  149  468  190  819 1303  872  584 1547  537  273  367  548  191   94\n",
      "  307   76 1334 1542   31  609  593  680]\n",
      "torch.Size([50, 9])\n",
      "torch.Size([50, 9])\n",
      "torch.Size([50, 9, 9])\n",
      "torch.Size([50, 13])\n",
      "torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "bs = 50\n",
    "sampler = MoleculeSampler(train_group, bs)\n",
    "\n",
    "# get a batch\n",
    "sz = sampler.choose_molecule_size()\n",
    "print(sz)\n",
    "indices = sampler.draw_batch_of_molecules(sz) \n",
    "print(indices)\n",
    "minibatch_node = torch.stack( [ train_group[sz][i].atom_type for i in indices] )\n",
    "print(minibatch_node.size())\n",
    "minibatch_pe  = torch.stack( [ train_group[sz][i].atom_type_pe  for i in indices] )\n",
    "print(minibatch_pe.size())\n",
    "minibatch_edge = torch.stack( [ train_group[sz][i].bond_type for i in indices] )\n",
    "print(minibatch_edge.size())\n",
    "minibatch_boa = torch.stack( [ train_group[sz][i].bag_of_atoms for i in indices] )\n",
    "print(minibatch_boa.size())\n",
    "minibatch_logP_SA_cycle_normalized = torch.stack( [ train_group[sz][i].logP_SA_cycle_normalized for i in indices] )\n",
    "print(minibatch_logP_SA_cycle_normalized.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-loading pytorch molecules (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "QM9_pytorch/\n",
      "Time: 1.1888618469238281\n",
      "['N', 'C', 'O', 'F', 'N H3 +', 'O -', 'C H1 -', 'N +', 'N -', 'N H1 -', 'C +', 'O +', 'N H2 +']\n",
      "{'N': 0, 'C': 1, 'O': 2, 'F': 3, 'N H3 +': 4, 'O -': 5, 'C H1 -': 6, 'N +': 7, 'N -': 8, 'N H1 -': 9, 'C +': 10, 'O +': 11, 'N H2 +': 12}\n",
      "['NONE', 'SINGLE', 'DOUBLE', 'TRIPLE']\n",
      "{'NONE': 0, 'SINGLE': 1, 'DOUBLE': 2, 'TRIPLE': 3}\n",
      "13 4\n",
      "tensor([1, 1, 2, 1, 1, 1, 1])\n",
      "tensor([0, 1, 0, 2, 3, 4, 5])\n",
      "tensor([[0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0]])\n",
      "tensor([0, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1.5990])\n",
      "CC(O)C1CC1C\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "start=time.time()\n",
    "\n",
    "data_folder_pytorch = 'QM9_pytorch/'\n",
    "# data_folder_pytorch = 'ZINC_pytorch/'\n",
    "print(data_folder_pytorch)\n",
    "\n",
    "with open(data_folder_pytorch+\"atom_dict.pkl\",\"rb\") as f:\n",
    "    atom_dict=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"bond_dict.pkl\",\"rb\") as f:\n",
    "    bond_dict=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"test_pytorch.pkl\",\"rb\") as f:\n",
    "    test=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"val_pytorch.pkl\",\"rb\") as f:\n",
    "    val=pickle.load(f)\n",
    "with open(data_folder_pytorch+\"train_pytorch.pkl\",\"rb\") as f:\n",
    "    train=pickle.load(f)\n",
    "print('Time:',time.time()-start)\n",
    "\n",
    "print(atom_dict.idx2word)\n",
    "print(atom_dict.word2idx)\n",
    "print(bond_dict.idx2word)\n",
    "print(bond_dict.word2idx)\n",
    "\n",
    "num_atom_type = len(atom_dict.idx2word)\n",
    "num_bond_type = len(bond_dict.idx2word)\n",
    "print(num_atom_type, num_bond_type)\n",
    "\n",
    "idx = 45\n",
    "print(train[idx].atom_type)\n",
    "print(train[idx].atom_type_pe)\n",
    "print(train[idx].bond_type)\n",
    "print(train[idx].bag_of_atoms)\n",
    "print(train[idx].logP_SA_cycle_normalized)\n",
    "print(train[idx].smile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions to generate DGL molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDGL(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, split):\n",
    "        self.split = split\n",
    "        with open(data_dir + \"/%s_pytorch.pkl\" % split,\"rb\") as f:\n",
    "            self.data = pickle.load(f)\n",
    "        num_graphs = len(self.data)\n",
    "        self.graph_lists = []\n",
    "        self.graph_labels = []\n",
    "        self.num_graphs = num_graphs\n",
    "        self._prepare()\n",
    "    def _prepare(self):\n",
    "        print(\"preparing %d graphs for the %s set...\" % (self.num_graphs, self.split.upper()))\n",
    "        for molecule in self.data:\n",
    "            node_features = molecule.atom_type.long()\n",
    "            adj = molecule.bond_type\n",
    "            edge_list = (adj != 0).nonzero() # converting adj matrix to edge_list\n",
    "            edge_idxs_in_adj = edge_list.split(1, dim=1)\n",
    "            edge_features = adj[edge_idxs_in_adj].reshape(-1).long()\n",
    "            # version 2020 -- tmp\n",
    "            #g = dgl.DGLGraph() # create the DGL graph\n",
    "            #g.add_nodes(molecule.num_atom)\n",
    "            #for src, dst in edge_list:\n",
    "            #    g.add_edges(src.item(), dst.item())  \n",
    "            # version 2023\n",
    "            g = dgl.graph((edge_list[:,0], edge_list[:,1]), num_nodes=molecule.num_atom) # create the DGL graph  \n",
    "            g.ndata['feat'] = node_features\n",
    "            g.edata['feat'] = edge_features\n",
    "            self.graph_lists.append(g)\n",
    "            self.graph_labels.append(molecule.logP_SA_cycle_normalized)\n",
    "    def __len__(self):\n",
    "        return self.num_graphs\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graph_lists[idx], self.graph_labels[idx]\n",
    "    \n",
    "class MoleculeDatasetDGL(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_name, data_dir):\n",
    "        t0 = time.time()\n",
    "        print('dataset: %s' % data_name)\n",
    "        with open(data_dir + \"/atom_dict.pkl\" ,\"rb\") as f: atom_dict = pickle.load(f)\n",
    "        with open(data_dir + \"/bond_dict.pkl\" ,\"rb\") as f: bond_dict = pickle.load(f)\n",
    "        self.num_atom_type = len(atom_dict)\n",
    "        self.num_bond_type = len(bond_dict)\n",
    "        self.train = MoleculeDGL(data_dir, 'train')\n",
    "        self.val   = MoleculeDGL(data_dir, 'val')\n",
    "        self.test  = MoleculeDGL(data_dir, 'test')\n",
    "        print(\"Time taken: {:.4f}s\".format(time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DGL datasets from pytorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: QM9\n",
      "preparing 2000 graphs for the TRAIN set...\n",
      "preparing 200 graphs for the VAL set...\n",
      "preparing 200 graphs for the TEST set...\n",
      "Time taken: 1.6281s\n",
      "2000\n",
      "200\n",
      "200\n",
      "(Graph(num_nodes=9, num_edges=20,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([-0.2620]))\n",
      "(Graph(num_nodes=9, num_edges=18,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([0.5061]))\n",
      "(Graph(num_nodes=9, num_edges=20,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([-4.4335]))\n",
      "Saving dgl molecules to folder : QM9_dgl/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: QM9_dgl/: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3.588580846786499\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "\n",
    "# Convert pytorch to dgl format\n",
    "dataset_name = 'QM9'\n",
    "# dataset_name = 'ZINC'\n",
    "dataset = MoleculeDatasetDGL(dataset_name, data_folder_pytorch) \n",
    "\n",
    "print(len(dataset.train))\n",
    "print(len(dataset.val))\n",
    "print(len(dataset.test))\n",
    "\n",
    "idx = 0\n",
    "print(dataset.train[idx])\n",
    "print(dataset.val[idx])\n",
    "print(dataset.test[idx])\n",
    "\n",
    "# Saving\n",
    "data_folder_dgl = 'QM9_dgl/'\n",
    "# data_folder_dgl = 'ZINC_dgl/'\n",
    "print('Saving dgl molecules to folder : ' + data_folder_dgl )\n",
    "os.system(\"mkdir \" + data_folder_dgl )\n",
    "with open(data_folder_dgl + \"/test_dgl.pkl\",\"wb\") as f:\n",
    "    pickle.dump(dataset.test,f)\n",
    "with open(data_folder_dgl +  \"/val_dgl.pkl\",\"wb\") as f:\n",
    "    pickle.dump(dataset.val,f)\n",
    "with open(data_folder_dgl +  \"/train_dgl.pkl\",\"wb\") as f:\n",
    "    pickle.dump(dataset.train,f)\n",
    "print('Time:',time.time()-start)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility class for loading DGL datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_name, data_dir):\n",
    "        start = time.time()\n",
    "        print(\"Loading datasets %s_dgl...\" % (data_name))\n",
    "        with open(data_dir + 'train_dgl.pkl',\"rb\") as f:\n",
    "            self.train = pickle.load(f)\n",
    "        with open(data_dir + 'val_dgl.pkl',\"rb\") as f:\n",
    "            self.val = pickle.load(f)\n",
    "        with open(data_dir + 'test_dgl.pkl',\"rb\") as f:\n",
    "            self.test = pickle.load(f)\n",
    "        print('train, test, val sizes :',len(self.train),len(self.test),len(self.val))\n",
    "        print(\"Time: {:.4f}s\".format(time.time()-start))\n",
    "    # form a mini batch from a given list of samples = [(graph, label) pairs]\n",
    "    # collate requires a method __getitem__ in the graph class used\n",
    "    def collate(self, samples):\n",
    "        # Input sample is a list of pairs (graph, label)\n",
    "        graphs, labels = map(list, zip(*samples))\n",
    "        batch_graphs = dgl.batch(graphs)\n",
    "        batch_labels = torch.stack(labels)\n",
    "        # Normalization w.r.t. graph sizes\n",
    "        tab_sizes_n = [ graphs[i].number_of_nodes() for i in range(len(graphs))]\n",
    "        tab_norm_n = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_n ]\n",
    "        batch_norm_n = torch.cat(tab_norm_n).sqrt()  \n",
    "        tab_sizes_e = [ graphs[i].number_of_edges() for i in range(len(graphs))]\n",
    "        tab_norm_e = [ torch.FloatTensor(size,1).fill_(1./float(size)) for size in tab_sizes_e ]\n",
    "        batch_norm_e = torch.cat(tab_norm_e).sqrt()\n",
    "        return batch_graphs, batch_labels, batch_norm_n, batch_norm_e\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DGL datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "4\n",
      "Loading datasets QM9_dgl...\n",
      "train, test, val sizes : 2000 200 200\n",
      "Time: 2.3155s\n",
      "2000\n",
      "200\n",
      "200\n",
      "([Graph(num_nodes=9, num_edges=20,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), Graph(num_nodes=9, num_edges=18,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)})], [tensor([-0.2620]), tensor([1.0906])])\n",
      "(Graph(num_nodes=9, num_edges=18,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([0.5061]))\n",
      "(Graph(num_nodes=9, num_edges=20,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([-4.4335]))\n"
     ]
    }
   ],
   "source": [
    "# Load the number of atom and bond types \n",
    "with open(data_folder_pytorch + \"/atom_dict.pkl\" ,\"rb\") as f: num_atom_type = len(pickle.load(f))\n",
    "with open(data_folder_pytorch + \"/bond_dict.pkl\" ,\"rb\") as f: num_bond_type = len(pickle.load(f))\n",
    "print(num_atom_type)\n",
    "print(num_bond_type)\n",
    "\n",
    "# Load the DGL datasets\n",
    "dataset_name = 'QM9'\n",
    "# dataset_name = 'ZINC'\n",
    "datasets_dgl = MoleculeDataset(dataset_name, data_folder_dgl)\n",
    "trainset, valset, testset = datasets_dgl.train, datasets_dgl.val, datasets_dgl.test\n",
    "\n",
    "print(len(trainset))\n",
    "print(len(valset))\n",
    "print(len(testset))\n",
    "\n",
    "idx = 0\n",
    "print(trainset[:2])\n",
    "print(valset[idx])\n",
    "print(testset[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate batch of graphs (of different sizes) with DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=879, num_edges=1886,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)})\n",
      "[tensor([-1.2537]), tensor([1.3803]), tensor([-1.3044]), tensor([-1.4180]), tensor([-0.2478]), tensor([-0.9695]), tensor([-0.4222]), tensor([0.3878]), tensor([-1.0161]), tensor([0.0748]), tensor([-0.0517]), tensor([-2.5762]), tensor([-1.5588]), tensor([-0.9627]), tensor([-0.8684]), tensor([-0.7091]), tensor([0.6806]), tensor([-1.3069]), tensor([-0.8694]), tensor([-1.5657]), tensor([0.2832]), tensor([0.9774]), tensor([-0.0191]), tensor([0.9235]), tensor([0.3156]), tensor([0.7727]), tensor([-0.1822]), tensor([0.2102]), tensor([-1.6419]), tensor([-2.0087]), tensor([2.5527]), tensor([-8.9879]), tensor([2.2164]), tensor([1.7668]), tensor([2.1484]), tensor([0.6698]), tensor([0.0472]), tensor([2.2352]), tensor([-2.9537]), tensor([-0.3383]), tensor([0.8908]), tensor([-1.6415]), tensor([2.0142]), tensor([-1.0754]), tensor([2.3651]), tensor([-0.3757]), tensor([-1.8514]), tensor([3.5977]), tensor([3.5412]), tensor([3.0768]), tensor([1.0893]), tensor([1.7048]), tensor([0.2616]), tensor([2.2620]), tensor([0.3140]), tensor([2.6396]), tensor([-3.5389]), tensor([-0.5714]), tensor([0.3690]), tensor([0.5096]), tensor([-2.1499]), tensor([2.0640]), tensor([-1.2224]), tensor([1.6025]), tensor([0.4237]), tensor([2.9983]), tensor([-2.5939]), tensor([2.4795]), tensor([0.8534]), tensor([0.6909]), tensor([-1.3397]), tensor([1.4151]), tensor([0.6170]), tensor([-0.5559]), tensor([2.2932]), tensor([-0.7318]), tensor([-1.2177]), tensor([0.6265]), tensor([1.9379]), tensor([0.2327]), tensor([0.4400]), tensor([-0.5830]), tensor([-2.1306]), tensor([-1.5767]), tensor([0.4913]), tensor([1.8945]), tensor([-4.7076]), tensor([-2.9729]), tensor([0.8757]), tensor([-0.8408]), tensor([3.8540]), tensor([0.2888]), tensor([-1.8562]), tensor([-1.3263]), tensor([-1.5393]), tensor([-1.2097]), tensor([-4.0474]), tensor([-0.5893]), tensor([1.1108]), tensor([1.8506])]\n",
      "torch.Size([879, 1])\n",
      "torch.Size([1886, 1])\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "batch_x torch.Size([883])\n",
      "batch_e torch.Size([1866])\n",
      "batch_norm_n torch.Size([883, 1])\n",
      "batch_norm_e torch.Size([1866, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, collate_fn=datasets_dgl.collate)\n",
    "\n",
    "batch_graphs, batch_labels, batch_norm_n, batch_norm_e = list(train_loader)[0]\n",
    "print(batch_graphs)\n",
    "print(batch_labels)\n",
    "print(batch_norm_n.size())\n",
    "print(batch_norm_e.size())\n",
    "\n",
    "for iter, (batch_graphs, batch_labels, batch_norm_n, batch_norm_e) in enumerate(train_loader):\n",
    "    print(iter)\n",
    "    \n",
    "batch_x = batch_graphs.ndata['feat']\n",
    "print('batch_x',batch_x.size())\n",
    "batch_e = batch_graphs.edata['feat']\n",
    "print('batch_e',batch_e.size())\n",
    "print('batch_norm_n',batch_norm_n.size())\n",
    "print('batch_norm_e',batch_norm_e.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
