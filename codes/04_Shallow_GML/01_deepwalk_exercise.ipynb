{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : Deepwalk technique - exercise\n",
    "\n",
    "Perozzi, Al-Rfou, Skiena, Deepwalk: Online learning of social representations, 2014  \n",
    "https://arxiv.org/pdf/1403.6652.pdf\n",
    "\n",
    "### Xavier Bresson\n",
    "\n",
    "<br>\n",
    "Notebook goals :<br> \n",
    "• Design a random walk extractor <br> \n",
    "• Implement the deepwalk technique <br> \n",
    "• Compare visually the deepwalk embedding with networkx visualization <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/GML_May23_codes/codes/04_Shallow_GML'\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"path_to_file\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n",
    "    !pip install rdkit # Install RDKit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pickle\n",
    "from utils import Molecule\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "from utils import compute_ncut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset and select one molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data')\n",
    "data_folder_pytorch = '../08_datasets/ZINC_pytorch/'\n",
    "#data_folder_pytorch = '../08_datasets/QM9_pytorch/'\n",
    "with open(data_folder_pytorch+\"train_pytorch.pkl\",\"rb\") as f:\n",
    "    dataset=pickle.load(f)\n",
    "\n",
    "# Select one molecule\n",
    "idx = 4 # QM9\n",
    "idx = 7 # QM9\n",
    "idx = 8 # ALL\n",
    "idx = 12\n",
    "mol = dataset[idx]\n",
    "print(mol.atom_type)\n",
    "print(mol.atom_type_pe)\n",
    "print(mol.bond_type)\n",
    "print(mol.bag_of_atoms)\n",
    "print(mol.logP_SA_cycle_normalized)\n",
    "print(mol.smile)\n",
    "Chem.MolFromSmiles(mol.smile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a class for extracting a random walk path and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class sample_RW_path:\n",
    "    \n",
    "    def __init__(self, num_steps, RW):\n",
    "        self.num_steps = num_steps # number of steps\n",
    "        self.RW = RW # random walk matrix\n",
    "        self.num_nodes = RW.size(0) # number of nodes\n",
    "        \n",
    "    def sample_walk(self, idx_start):\n",
    "        idx = torch.tensor(idx_start).long() # starting index of the walk\n",
    "        RWpath = [idx] # random walk path\n",
    "        for _ in range(self.num_steps-1):\n",
    "        #for _ in range(### YOUR CODE HERE): # sample \"num_steps-1\" nodes\n",
    "            # sample the next node from the RW probability prob_j = sample(RW[i,:]\n",
    "            # use Bernoulli sampling with torch.distributions.Categorical(prob).sample()\n",
    "            idx =  ### YOUR CODE HERE\n",
    "            RWpath.append(idx) # append sampled node to the path\n",
    "        RWpath = torch.stack(RWpath).flatten() # path format = torch.tensor([idx_1, idx_2, ..., idx_num_steps])\n",
    "        return RWpath\n",
    "\n",
    "# RW operator\n",
    "A = (mol.bond_type>0).float() # Adjacency matrix\n",
    "D = A.sum(dim=0) # Degree vector\n",
    "Dinv = (D**(-1)).diag() # Inverse degree matrix\n",
    "RW = torch.mm(Dinv,A) # RW matrix\n",
    "#print(RW)\n",
    "#print(RW.sum(dim=1)) # sanity check, probability sums to 1\n",
    "\n",
    "# Sample one RW path\n",
    "num_RW_steps = 4 # QM9\n",
    "num_RW_steps = 12 # ZINC\n",
    "generator = sample_RW_path(num_RW_steps, RW) # instantiate RW class\n",
    "walk = generator.sample_walk(7) # sample RW path starting with index=7\n",
    "print('RW:',walk)\n",
    "\n",
    "# Check visually RW path correctness\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "A_nx = nx.from_numpy_array(A.numpy())\n",
    "C = compute_ncut(A.long(), 4)\n",
    "nx.draw(A_nx, ax=ax, node_color=C, cmap='jet', with_labels=True, font_size=10) # visualise node indexes\n",
    "ax.title.set_text('Molecule visualization with networkx')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a class of deepwalk network and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class deepwalk_net(nn.Module): \n",
    "    \n",
    "    def __init__(self, num_nodes, hidden_dim, num_negative):\n",
    "        super(deepwalk_net, self).__init__()\n",
    "        print(num_nodes, hidden_dim)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_negative = num_negative\n",
    "        self.node_embedding = nn.Embedding(num_nodes, hidden_dim)\n",
    "\n",
    "    def forward(self, walk):\n",
    "        walk_list = walk.tolist() # list nodes in RW\n",
    "        node_list = list(range(self.num_nodes)) # list all nodes\n",
    "        list_negative = torch.tensor(list(set(node_list) - set(walk_list))) # all possible negative samples\n",
    "        #list_negative = list_negative[torch.randperm(list_negative.size(0))] # ???\n",
    "        loss = []\n",
    "        for i in walk: # loop over all nodes in RW\n",
    "                       # node i that must predict all other nodes j in RW\n",
    "                \n",
    "            # positive samples\n",
    "            # extract embedding hi of node i\n",
    "            # hi.size()=(1,hidden_dim), you may use \".unsqueeze()\"\n",
    "            hi = ### YOUR CODE HERE\n",
    "            # extract embedding hj of nodes j in RW\n",
    "            j = torch.tensor(list(set(walk_list) - set([i.detach().item()]))) # all other nodes j in RW\n",
    "            # hj.size()=(num_RW_steps-1,hidden_dim), you may use \".transpose()\"\n",
    "            hj = ### YOUR CODE HERE\n",
    "            \n",
    "            # negative samples : select randomly \"num_negative\" nodes which are not in the RW path\n",
    "            list_negative = list_negative[torch.randperm(list_negative.size(0))][:self.num_negative] # select randomly \"num_negative\" negative samples\n",
    "            # extract embedding hk of nodes k not in RW \n",
    "            # hk.size()=(num_negative,hidden_dim), you may use \".transpose()\"\n",
    "            hk = ### YOUR CODE HERE\n",
    "            \n",
    "            # compute loss\n",
    "            loss_i = - ( torch.log(torch.sigmoid(torch.mm(hi,hj))).sum() - 0.25*torch.log(torch.sigmoid(torch.mm(hi,hk))).sum() )\n",
    "            loss.append(loss_i)\n",
    "        loss = torch.stack(loss).mean()\n",
    "        return loss\n",
    "\n",
    "# Instantiate a deepwalk network\n",
    "num_nodes = A.size(0)\n",
    "net = deepwalk_net(num_nodes, 2, num_RW_steps//4) # select num_negative = num_RW_steps/4\n",
    "print(net)\n",
    "\n",
    "# Train the network\n",
    "optimizer = torch.optim.Adam( net.parameters() , lr=0.001 ) \n",
    "for iter in range(300): \n",
    "    loss_epoch = 0.0\n",
    "    for idx in torch.randperm(num_nodes).tolist(): # shuffle ordering of nodes\n",
    "        walk = generator.sample_walk(idx)\n",
    "        loss = net(walk)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.detach()\n",
    "        with torch.no_grad():\n",
    "            # centering the embedding coordinates\n",
    "            # helps optimization by reducing one degree of freedom\n",
    "            net.node_embedding.weight.sub_(net.node_embedding.weight.mean(dim=0)) \n",
    "    # plot the loss value\n",
    "    if not iter%10:\n",
    "        print(iter,loss_epoch/num_nodes)\n",
    "            \n",
    "# Visualize the 2D coordinates of the node embeddings\n",
    "x = net.node_embedding.weight.detach()\n",
    "print(x,x.size())\n",
    "\n",
    "# plot 2D coordinates\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(x[:,0], x[:,1])\n",
    "idx = list(range(num_nodes))\n",
    "ax.scatter(x[:,0], x[:,1], c=C, cmap='jet')\n",
    "for i, txt in enumerate(idx):\n",
    "    ax.annotate(txt, (x[:,0][i], x[:,1][i]), textcoords=\"offset points\", xytext=(1,5))\n",
    "ax.title.set_text('2D embdding of nodes')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with graph edges\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "nx.draw(A_nx, ax=ax, node_color=C, cmap='jet', with_labels=True, font_size=10) # visualise node indexes\n",
    "ax.title.set_text('Molecular graph')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
